
LLM_SERVING=openai
LLM_FLASH_MODEL=llama3.3-ffm-70b-32k-chat
LLM_THINKING_MODEL=llama3.3-ffm-70b-32k-chat
LLM_MAX_CTX=32768

SERVING_BASE_URL=https://api-ams.twcc.ai/api/models
SERVING_API_KEY=<your TWSCC api key>
